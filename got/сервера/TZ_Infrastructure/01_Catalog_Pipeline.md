# UNDE Infrastructure ‚Äî –ö–∞—Ç–∞–ª–æ–≥: —Å–±–æ—Ä, —Ñ–æ—Ç–æ, —Ö—Ä–∞–Ω–µ–Ω–∏–µ

*–°–µ—Ä–≤–µ—Ä—ã –∫–∞—Ç–∞–ª–æ–∂–Ω–æ–≥–æ pipeline.*

> **üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–¥ [Pipeline v5.1](../../UNDE_Fashion_Recognition_Pipeline_v5.1.md)** ‚Äî 2 —Ñ–æ—Ç–æ/SKU –≤ Ximilar, –Ω–æ–≤—ã–µ –ø–æ–ª—è –≤ raw_products (index_scope, ximilar_synced_urls, ximilar_target_count), –Ω–æ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã availability.

---

## 1. SCRAPER SERVER (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π)

### –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|
| **Hostname** | scraper |
| **Private IP** | 10.1.0.3 |
| **Public IP** | 46.62.255.184 |
| **–¢–∏–ø** | CPX22 |
| **–°—Ç–∞—Ç—É—Å** | ‚úÖ –°—É—â–µ—Å—Ç–≤—É–µ—Ç |

### –ó–∞–¥–∞—á–∏ (–æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ)

| –ó–∞–¥–∞—á–∞ | –ß–∞—Å—Ç–æ—Ç–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|---------|----------|
| **availability_poll** | –ö–∞–∂–¥—ã–π —á–∞—Å (:00) | Mobile API ‚Üí Staging DB (–Ω–∞–ª–∏—á–∏–µ –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö Dubai) |
| **sync_to_production** | –ö–∞–∂–¥—ã–π —á–∞—Å (:10) | Staging DB ‚Üí Production DB (verified –¥–∞–Ω–Ω—ã–µ) |

### –ß—Ç–æ –ù–ï –¥–µ–ª–∞–µ—Ç

- ‚ùå –°–±–æ—Ä –∫–∞—Ç–∞–ª–æ–≥–∞ (—ç—Ç–æ Apify Server)
- ‚ùå –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ (—ç—Ç–æ Apify Server)
- ‚ùå –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ (—ç—Ç–æ Collage Server)

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```bash
# /opt/unde/scraper/.env

# Staging DB
STAGING_DB_URL=postgresql://scraper:xxx@10.1.0.8:6432/unde_staging

# Production DB
PRODUCTION_DB_URL=postgresql://undeuser:xxx@10.1.1.2:6432/unde_main

# Mobile API
ZARA_USER_AGENT=ZaraApp/15.10.0 ...

# Dubai stores
DUBAI_ZARA_STORES=PLACEHOLDER_STORE_IDS
```

---

## 2. APIFY SERVER (‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç)

### –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|
| **Hostname** | apify |
| **Private IP** | 10.1.0.9 |
| **Public IP** | 89.167.110.186 |
| **–¢–∏–ø** | Hetzner CX23 |
| **vCPU** | 2 |
| **RAM** | 4 GB |
| **Disk** | 40 GB NVMe |
| **OS** | Ubuntu 24.04 LTS |
| **Git** | http://gitlab-real.unde.life/unde/apify.git |
| **–°—Ç–∞—Ç—É—Å** | ‚úÖ –†–∞–∑–≤—ë—Ä–Ω—É—Ç, –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã running |

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–¢–æ–ª—å–∫–æ —Å–±–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ —Ç–æ–≤–∞—Ä–∞—Ö —á–µ—Ä–µ–∑ Apify.com scrapers:
- –í—ã–∑–æ–≤ Apify scrapers (—Ä–µ–∑–∏–¥–µ–Ω—Ç–Ω—ã–µ –ø—Ä–æ–∫—Å–∏)
- –ü–æ–ª—É—á–µ–Ω–∏–µ JSON —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏: –Ω–∞–∑–≤–∞–Ω–∏–µ, —Ü–µ–Ω–∞, —Ä–∞–∑–º–µ—Ä—ã, –∫–∞—Ç–µ–≥–æ—Ä–∏—è, URL —Ñ–æ—Ç–æ
- –ó–∞–ø–∏—Å—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ Staging DB (image_status='pending')

### –ß—Ç–æ –ù–ï –¥–µ–ª–∞–µ—Ç

- ‚ùå –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ (—ç—Ç–æ Photo Downloader, 10.1.0.10)
- ‚ùå Upload —Ñ–æ—Ç–æ –≤ Object Storage (—ç—Ç–æ Photo Downloader)
- ‚ùå –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å Ximilar (—ç—Ç–æ Ximilar Sync, 10.1.0.11)

### –ó–∞–¥–∞—á–∏

| –ó–∞–¥–∞—á–∞ | –ß–∞—Å—Ç–æ—Ç–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|---------|----------|
| **apify_zara** | –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ, –í—Å 02:00 | –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ Zara (~15K —Ç–æ–≤–∞—Ä–æ–≤) |
| **apify_bershka** | –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ, –í—Å 03:00 | –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ Bershka (~8K —Ç–æ–≤–∞—Ä–æ–≤) |
| **apify_pullandbear** | –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ, –í—Å 04:00 | –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ Pull&Bear (~6K —Ç–æ–≤–∞—Ä–æ–≤) |
| **apify_stradivarius** | –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ, –í—Å 05:00 | –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ Stradivarius (~8K —Ç–æ–≤–∞—Ä–æ–≤) |
| **apify_massimodutti** | –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ, –í—Å 06:00 | –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ Massimo Dutti (~5K —Ç–æ–≤–∞—Ä–æ–≤) |
| **apify_oysho** | –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ, –í—Å 07:00 | –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ Oysho (~5K —Ç–æ–≤–∞—Ä–æ–≤) |

### Docker Compose

```yaml
services:
  apify-collector:
    build: .
    container_name: apify-collector
    restart: unless-stopped
    command: celery -A app.celery_app worker --loglevel=info --concurrency=2
    env_file: .env
    deploy:
      resources:
        limits:
          memory: 2G

  apify-beat:
    build: .
    container_name: apify-beat
    restart: unless-stopped
    command: celery -A app.celery_app beat --loglevel=info --schedule=/app/data/celerybeat-schedule
    env_file: .env
```

> node_exporter v1.8.2 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–∞–∫ systemd —Å–µ—Ä–≤–∏—Å (0.0.0.0:9100), –Ω–µ –≤ Docker.

### Environment Variables

```bash
# /opt/unde/apify/.env

APIFY_TOKEN=<Apify PAT token>
STAGING_DB_URL=postgresql://apify:<password>@10.1.0.8:6432/unde_staging
REDIS_URL=redis://:<password>@10.1.0.4:6379/7
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Apify

**–ü–∞—Ç—Ç–µ—Ä–Ω:** –ò—Å–ø–æ–ª—å–∑—É–µ–º Apify Tasks (–Ω–µ –∞–∫—Ç–æ—Ä –Ω–∞–ø—Ä—è–º—É—é). Task ‚Äî –ø—Ä–µ–¥–Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ –∞–∫—Ç–æ—Ä–∞
—Å –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (URL, maxItems, region). –°–æ–∑–¥–∞—ë—Ç—Å—è —á–µ—Ä–µ–∑ UI Apify.

**–ê–∫—Ç–æ—Ä:** `datasaurus/zara` (–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–µ –¥–ª—è –¥—Ä—É–≥–∏—Ö –±—Ä–µ–Ω–¥–æ–≤).

```python
# celery_app.py ‚Äî –º–∞–ø–ø–∏–Ω–≥ –±—Ä–µ–Ω–¥ ‚Üí Apify Task ID
BRAND_TASKS = {
    "zara": "z1psVOTyIKFdU5N9n",
    # "bershka": "TASK_ID_HERE",       # TODO: —Å–æ–∑–¥–∞—Ç—å Task –≤ Apify UI
    # "pullandbear": "TASK_ID_HERE",
    # "stradivarius": "TASK_ID_HERE",
    # "massimodutti": "TASK_ID_HERE",
    # "oysho": "TASK_ID_HERE",
}
```

### –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –æ—Ç Apify (datasaurus/zara)

```json
{
  "id": 512913640,
  "reference": "02086797-V2026",
  "brand": "Zara",
  "name": "ZW COLLECTION ASYMMETRIC BLAZER",
  "description": "Blazer with a notched lapel collar...",
  "price": 69900,                    // ‚Üê –≤ —Ñ–∏–ª—Å–∞—Ö! AED = price / 100 ‚Üí 699.00
  "category": "woman-outerwear-padded",
  "colors": "Black",
  "sizes": "XS, S, M, L",
  "detailedComposition": { "parts": [...] },
  "colorsSizesImagesJSON": [         // ‚Üê –º–∞—Å—Å–∏–≤ –ø–æ —Ü–≤–µ—Ç–∞–º
    {
      "id": "800",                   // color ID
      "name": "Black",
      "productId": 512918856,
      "xmedia": [                    // ‚Üê URL —Ñ–æ—Ç–æ —Å {width} –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–º
        "https://static.zara.net/.../02086797800-p.jpg?w={width}",
        "https://static.zara.net/.../02086797800-e1.jpg?w={width}",
        "https://static.zara.net/.../02086797800-e2.jpg?w={width}",
        "https://static.zara.net/.../02086797800-e3.jpg?w={width}"
      ],
      "sizes": [
        { "name": "XS", "sku": 512913641, "availability": "in_stock", "price": 69900 },
        { "name": "S",  "sku": 512913642, "availability": "in_stock", "price": 69900 }
      ]
    }
  ]
}
```

### –ü—Ä–æ—Ü–µ—Å—Å —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

```python
from apify_client import ApifyClient

def collect_brand(brand: str, task_id: str):
    client = ApifyClient(os.environ["APIFY_TOKEN"])

    # 1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–µ–¥–Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π Task (–Ω–µ actor.call!)
    task_client = client.task(task_id)
    run = task_client.call()  # –±–ª–æ–∫–∏—Ä—É—é—â–∏–π –≤—ã–∑–æ–≤, –∂–¥—ë—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è

    # 2. –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    dataset = client.dataset(run["defaultDatasetId"])

    for item in dataset.iterate_items():
        # 3. –ò–∑–≤–ª–µ—á—å —Ñ–æ—Ç–æ URL'—ã –∏–∑ –≤—Å–µ—Ö —Ü–≤–µ—Ç–æ–≤
        photo_urls = []
        for color in item.get("colorsSizesImagesJSON", []):
            for url in color.get("xmedia", [])[:5]:
                # –ó–∞–º–µ–Ω–∏—Ç—å {width} –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                photo_urls.append(url.replace("{width}", "1920"))

        # 4. –¶–µ–Ω–∞: fils ‚Üí AED (√∑100)
        price_aed = item["price"] / 100 if item.get("price") else None

        # 5. –ó–∞–ø–∏—Å–∞—Ç—å –≤ Staging DB (—Ñ–æ—Ç–æ –ù–ï —Å–∫–∞—á–∏–≤–∞–µ–º, —Ç–æ–ª—å–∫–æ URL'—ã)
        db.execute("""
            INSERT INTO raw_products (source, external_id, brand, name, price,
                                      currency, category, colour, sizes,
                                      composition, description,
                                      original_image_urls, image_status,
                                      raw_data, scraped_at)
            VALUES (%s, %s, %s, %s, %s,
                    'AED', %s, %s, %s,
                    %s, %s,
                    %s, 'pending',
                    %s, NOW())
            ON CONFLICT (source, external_id) DO UPDATE SET
                name = EXCLUDED.name,
                price = EXCLUDED.price,
                original_image_urls = EXCLUDED.original_image_urls,
                raw_data = EXCLUDED.raw_data,
                scraped_at = EXCLUDED.scraped_at,
                updated_at = NOW()
        """, f"apify_{brand}", str(item["id"]), brand, item["name"],
             price_aed, item.get("category"), item.get("colors"),
             json.dumps(item.get("sizes", "")),
             json.dumps(item.get("detailedComposition")),
             item.get("description"),
             json.dumps(photo_urls), json.dumps(item))
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π

```
/opt/unde/apify/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ celery_app.py
‚îÇ   ‚îú‚îÄ‚îÄ tasks.py
‚îÇ   ‚îú‚îÄ‚îÄ collectors/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ zara.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bershka.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ db.py
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ run-brand.sh
‚îÇ   ‚îî‚îÄ‚îÄ health-check.sh
‚îî‚îÄ‚îÄ data/
```

---

## 3. PHOTO DOWNLOADER (‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç)

### –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|
| **Hostname** | photo-downloader |
| **Private IP** | 10.1.0.10 |
| **Public IP** | 89.167.99.242 |
| **–¢–∏–ø** | Hetzner CX23 |
| **vCPU** | 2 |
| **RAM** | 4 GB |
| **Disk** | 40 GB NVMe |
| **OS** | Ubuntu 24.04 LTS |
| **Git** | http://gitlab-real.unde.life/unde/photo-downloader.git |
| **–°—Ç–∞—Ç—É—Å** | ‚úÖ –†–∞–∑–≤—ë—Ä–Ω—É—Ç, –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã running |

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä–æ–≤ —Å —Å–∞–π—Ç–æ–≤ –±—Ä–µ–Ω–¥–æ–≤ **—á–µ—Ä–µ–∑ Bright Data residential proxy** –∏ upload –≤ Object Storage:
- –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç Staging DB –Ω–∞ –∑–∞–ø–∏—Å–∏ —Å `image_status='pending'`
- –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–æ—Ç–æ –ø–æ URL –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ (–¥–æ 5 —Ñ–æ—Ç–æ –Ω–∞ —Ç–æ–≤–∞—Ä)
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤ Object Storage (`/originals/`) –Ω–∞–ø—Ä—è–º—É—é (–±–µ–∑ –ø—Ä–æ–∫—Å–∏)
- –û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –Ω–∞ `image_status='uploaded'`

### –ü–æ—á–µ–º—É –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä

- **–°–∞–º–∞—è —Ö—Ä—É–ø–∫–∞—è —á–∞—Å—Ç—å pipeline:** –±—Ä–µ–Ω–¥—ã –±–ª–æ–∫–∏—Ä—É—é—Ç IP, —Ç–∞–π–º–∞—É—Ç—ã, rate limits, –∫–∞–ø—á–∏
- **–°–∞–º–∞—è —Ç—è–∂—ë–ª–∞—è –ø–æ —Ç—Ä–∞—Ñ–∏–∫—É:** ~47K —Ç–æ–≤–∞—Ä–æ–≤ √ó 5 —Ñ–æ—Ç–æ √ó 300KB = ~70 GB –∑–∞ –æ–¥–∏–Ω —Ü–∏–∫–ª
- **–†–∞–∑–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –æ—Ç–∫–∞–∑–æ–≤:** Apify API –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å, –∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ ‚Äî –Ω–µ—Ç (–∏ –Ω–∞–æ–±–æ—Ä–æ—Ç)
- **Residential proxy:** Bright Data ‚Äî –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å —Å –Ω–æ–≤–æ–≥–æ residential IP, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–æ—Ç–∞—Ü–∏—è

### –ó–∞–¥–∞—á–∏

| –ó–∞–¥–∞—á–∞ | –ß–∞—Å—Ç–æ—Ç–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|---------|----------|
| **download_pending** | –ö–∞–∂–¥—ã–µ 15 –º–∏–Ω | –°–∫–∞—á–∞—Ç—å —Ñ–æ—Ç–æ –¥–ª—è —Ç–æ–≤–∞—Ä–æ–≤ —Å image_status='pending' |
| **retry_failed** | –ö–∞–∂–¥—ã–π —á–∞—Å (:30) | –ü–æ–≤—Ç–æ—Ä–∏—Ç—å –Ω–µ—É–¥–∞—á–Ω—ã–µ (image_status='error') |
| **cleanup_temp** | –ï–∂–µ–¥–Ω–µ–≤–Ω–æ 05:00 | –û—á–∏—Å—Ç–∏—Ç—å /app/data |

### Docker Compose

```yaml
services:
  photo-downloader:
    build: .
    container_name: photo-downloader
    restart: unless-stopped
    command: celery -A app.celery_app worker --loglevel=info --concurrency=2
    env_file: .env
    volumes:
      - ./app:/app/app
      - ./data:/app/data
    deploy:
      resources:
        limits:
          memory: 2G

  downloader-beat:
    build: .
    container_name: downloader-beat
    restart: unless-stopped
    command: celery -A app.celery_app beat --loglevel=info --schedule=/app/data/celerybeat-schedule
    env_file: .env
    volumes:
      - ./app:/app/app
      - ./data:/app/data
```

> node_exporter v1.8.2 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–∞–∫ systemd —Å–µ—Ä–≤–∏—Å (0.0.0.0:9100), –Ω–µ –≤ Docker.

### Environment Variables

```bash
# /opt/unde/photo-downloader/.env

STAGING_DB_URL=postgresql://downloader:<password>@10.1.0.8:6432/unde_staging
REDIS_URL=redis://:<password>@10.1.0.4:6379/7
PROXY_URL=http://brd-customer-hl_b9a99adf-zone-zara:<password>@brd.superproxy.io:33335
S3_ENDPOINT=https://hel1.your-objectstorage.com
S3_ACCESS_KEY=<access_key>
S3_SECRET_KEY=<secret_key>
S3_BUCKET=unde-images
DOWNLOAD_TIMEOUT=30
MAX_RETRIES=3
BATCH_SIZE=200
CONCURRENT_DOWNLOADS=10
```

### Bright Data Proxy

–í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ –∏–¥—É—Ç —á–µ—Ä–µ–∑ Bright Data residential proxy.
Upload –≤ S3 –∏–¥—ë—Ç –Ω–∞–ø—Ä—è–º—É—é (–±–µ–∑ –ø—Ä–æ–∫—Å–∏).

| –ú–µ—Ö–∞–Ω–∏–∑–º | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|----------|
| –ü—Ä–æ–≤–∞–π–¥–µ—Ä | Bright Data (brd.superproxy.io:33335) |
| –¢–∏–ø | Residential ‚Äî –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å —Å –Ω–æ–≤–æ–≥–æ IP |
| User-Agent | –†–æ—Ç–∞—Ü–∏—è –∏–∑ 8 —Ä–µ–∞–ª—å–Ω—ã—Ö –±—Ä–∞—É–∑–µ—Ä–Ω—ã—Ö —Å—Ç—Ä–æ–∫ |
| Rate limiting | Max 10 concurrent |
| Delay | 0.5‚Äì2 —Å–µ–∫ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ |
| Backoff | –ü—Ä–∏ 429/503: 5s ‚Üí 15s ‚Üí 45s ‚Üí error |
| Timeout | 30 —Å–µ–∫ –Ω–∞ —Ñ–æ—Ç–æ, 120 —Å–µ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä |

### –ü—Ä–æ—Ü–µ—Å—Å —Å–∫–∞—á–∏–≤–∞–Ω–∏—è

```python
import aiohttp, asyncio

async def download_pending():
    products = db.query("""
        SELECT id, external_id, brand, original_image_urls
        FROM raw_products
        WHERE image_status = 'pending'
        LIMIT 200
    """)

    proxy = os.environ["PROXY_URL"]

    async with aiohttp.ClientSession() as session:
        for product in products:
            try:
                uploaded_urls = []
                for i, url in enumerate(product.original_image_urls[:5]):
                    # –ó–∞–º–µ–Ω–∏—Ç—å {width} –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
                    url = url.replace("{width}", "1920")

                    # –°–∫–∞—á–∞—Ç—å —á–µ—Ä–µ–∑ Bright Data residential proxy
                    async with session.get(url, proxy=proxy, ssl=False,
                                           timeout=aiohttp.ClientTimeout(total=30),
                                           headers={"User-Agent": random_ua()}) as resp:
                        data = await resp.read()

                    # –í–∞–ª–∏–¥–∞—Ü–∏—è (Pillow)
                    Image.open(io.BytesIO(data)).verify()

                    # Upload –≤ S3 –Ω–∞–ø—Ä—è–º—É—é (–±–µ–∑ proxy)
                    key = f"originals/{product.brand}/{product.external_id}/{i+1}.jpg"
                    s3.upload_fileobj(io.BytesIO(data), S3_BUCKET, key)
                    uploaded_urls.append(
                        f"https://unde-images.hel1.your-objectstorage.com/{key}")

                db.execute("""
                    UPDATE raw_products
                    SET image_urls = %s, image_status = 'uploaded', updated_at = NOW()
                    WHERE id = %s
                """, json.dumps(uploaded_urls), product.id)
            except Exception as e:
                db.execute("""
                    UPDATE raw_products
                    SET image_status = 'error', error_message = %s, updated_at = NOW()
                    WHERE id = %s
                """, str(e), product.id)
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π

```
/opt/unde/photo-downloader/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ celery_app.py
‚îÇ   ‚îú‚îÄ‚îÄ tasks.py
‚îÇ   ‚îú‚îÄ‚îÄ downloader.py
‚îÇ   ‚îú‚îÄ‚îÄ storage.py
‚îÇ   ‚îî‚îÄ‚îÄ db.py
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ health-check.sh
‚îÇ   ‚îî‚îÄ‚îÄ test-download.sh
‚îî‚îÄ‚îÄ data/               # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–æ—á–∏—â–∞–µ—Ç—Å—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ)
```

---

## 4. XIMILAR SYNC SERVER (‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç)

### –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|
| **Hostname** | ximilar-sync |
| **Private IP** | 10.1.0.11 |
| **Public IP** | 89.167.93.187 |
| **–¢–∏–ø** | Hetzner CX23 |
| **vCPU** | 2 |
| **RAM** | 4 GB |
| **Disk** | 40 GB NVMe |
| **OS** | Ubuntu 24.04 LTS |
| **Git** | http://gitlab-real.unde.life/unde/ximilar-sync.git |
| **–°—Ç–∞—Ç—É—Å** | ‚úÖ –†–∞–∑–≤—ë—Ä–Ω—É—Ç, –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã running |

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ (üîÑ v5.1: selective sync)

–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ –≤ Ximilar Collection (–¥–ª—è Fashion Recognition Pipeline):
- –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç Staging DB –Ω–∞ –∑–∞–ø–∏—Å–∏ —Å `ximilar_status IN ('pending', 'partial')` –∏ `image_status` IN ('uploaded', 'collage_ready')
- **üîÑ v5.1:** –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–ª—å–∫–æ **2 —Ñ–æ—Ç–æ/SKU** (on-model + front) –≤–º–µ—Å—Ç–æ –≤—Å–µ—Ö 5-7. –≠–∫–æ–Ω–æ–º–∏—è -60% insert credits
- **üîÑ v5.1:** –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ `index_scope = 'pilot'` ‚Äî —Ç–æ–ª—å–∫–æ –ø–∏–ª–æ—Ç–Ω—ã–µ –±—Ä–µ–Ω–¥—ã –≥—Ä—É–∑—è—Ç—Å—è –≤ Ximilar
- **üîÑ v5.1:** Idempotent ‚Äî –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç `ximilar_synced_urls`, –Ω–µ –ø–µ—Ä–µ–æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–æ—Ç–æ
- –û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å: `'pending'` ‚Üí `'partial'` ‚Üí `'synced'`

### –ü–æ—á–µ–º—É –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä

- **–î—Ä—É–≥–æ–π –≤–Ω–µ—à–Ω–∏–π API:** Ximilar –∏–º–µ–µ—Ç —Å–≤–æ–∏ rate limits, —Å–≤–æ—ë downtime ‚Äî –Ω–µ —Å–≤—è–∑–∞–Ω–æ —Å Apify –∏–ª–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ–º —Ñ–æ—Ç–æ
- **–î—Ä—É–≥–∞—è —á–∞—Å—Ç–æ—Ç–∞:** –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —á–∞—â–µ –∏–ª–∏ —Ä–µ–∂–µ, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Å–±–æ—Ä–∞ –∫–∞—Ç–∞–ª–æ–≥–∞
- **–ò–∑–æ–ª—è—Ü–∏—è:** –ø—Ä–æ–±–ª–µ–º—ã —Å Ximilar –Ω–µ –±–ª–æ–∫–∏—Ä—É—é—Ç —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ

### –ü–æ—á–µ–º—É CX23

–õ—ë–≥–∫–∞—è –∑–∞–¥–∞—á–∞: —á–∏—Ç–∞–µ—Ç URL'—ã –∏–∑ Staging DB, –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç POST –≤ Ximilar API. I/O bound, –º–∏–Ω–∏–º—É–º CPU/RAM.

### –ó–∞–¥–∞—á–∏

| –ó–∞–¥–∞—á–∞ | –ß–∞—Å—Ç–æ—Ç–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|---------|----------|
| **ximilar_sync** | –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ, –í—Å 10:00 | –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –Ω–æ–≤—ã—Ö/–æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã—Ö SKU ‚Üí Ximilar Collection |
| **ximilar_retry** | –ï–∂–µ–¥–Ω–µ–≤–Ω–æ, 12:00 | –ü–æ–≤—Ç–æ—Ä–∏—Ç—å –Ω–µ—É–¥–∞—á–Ω—ã–µ (ximilar_status='error') |

### Docker Compose

```yaml
services:
  ximilar-sync:
    build: .
    container_name: ximilar-sync
    restart: unless-stopped
    command: celery -A app.celery_app worker --loglevel=info --concurrency=2
    env_file: .env
    volumes:
      - ./app:/app/app
      - ./data:/app/data
    deploy:
      resources:
        limits:
          memory: 1G

  ximilar-beat:
    build: .
    container_name: ximilar-beat
    restart: unless-stopped
    command: celery -A app.celery_app beat --loglevel=info --schedule=/app/data/celerybeat-schedule
    env_file: .env
    volumes:
      - ./app:/app/app
      - ./data:/app/data
```

> node_exporter v1.8.2 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–∞–∫ systemd —Å–µ—Ä–≤–∏—Å (0.0.0.0:9100), –Ω–µ –≤ Docker.

### Environment Variables

```bash
# /opt/unde/ximilar-sync/.env

# Staging DB
STAGING_DB_URL=postgresql://ximilar:<password>@10.1.0.8:6432/unde_staging

# Ximilar
XIMILAR_API_TOKEN=xxx                    # TODO: –∑–∞–ø–æ–ª–Ω–∏—Ç—å –∫–æ–≥–¥–∞ –ø–æ–ª—É—á–∏–º –æ—Ç Ximilar
XIMILAR_COLLECTION_ID=xxx               # TODO: –∑–∞–ø–æ–ª–Ω–∏—Ç—å –∫–æ–≥–¥–∞ –ø–æ–ª—É—á–∏–º –æ—Ç Ximilar
XIMILAR_API_URL=https://api.ximilar.com
XIMILAR_RATE_LIMIT=10

# Redis (Push Server)
REDIS_URL=redis://:<password>@10.1.0.4:6379/7

# Application
BATCH_SIZE=1000
```

### –ü—Ä–æ—Ü–µ—Å—Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (üîÑ v5.1: selective, idempotent)

```python
# –ü—Å–µ–≤–¥–æ–∫–æ–¥ (üîÑ v5.1: 2 —Ñ–æ—Ç–æ/SKU, index_scope filter, idempotency)

def sync_to_ximilar():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å 2 —Ñ–æ—Ç–æ/SKU (on-model + front) –≤ Ximilar Collection.
    üîÑ v5.1: —Ç–æ–ª—å–∫–æ –ø–∏–ª–æ—Ç–Ω—ã–µ –±—Ä–µ–Ω–¥—ã (index_scope='pilot'),
    idempotent —á–µ—Ä–µ–∑ ximilar_synced_urls, progressive ingestion."""
    products = db.query("""
        SELECT id, external_id, brand, name, category, price,
               image_urls, ximilar_synced_urls, ximilar_target_count
        FROM raw_products
        WHERE image_status IN ('uploaded', 'collage_ready')
          AND ximilar_status IN ('pending', 'partial')
          AND index_scope = 'pilot'                    -- üîÑ v5.1: —Ç–æ–ª—å–∫–æ –ø–∏–ª–æ—Ç–Ω—ã–µ
        LIMIT 1000
    """)

    for product in products:
        try:
            # üîÑ v5.1: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ target_count —Ñ–æ—Ç–æ (default: 2)
            target = product.ximilar_target_count or 2
            images = product.image_urls[:target]
            synced = set(product.ximilar_synced_urls or [])

            # üîÑ v5.1: idempotency ‚Äî –Ω–µ –ø–µ—Ä–µ–æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ
            to_send = [url for url in images if url not in synced]

            if to_send:
                ximilar.add_images(
                    collection_id=XIMILAR_COLLECTION_ID,
                    images=[{"url": url} for url in to_send],
                    metadata={
                        "sku_id": product.external_id,
                        "brand": product.brand,
                        "name": product.name,
                        "category": product.category,
                        "price": str(product.price)
                        # üîÑ v5.1: –ù–ï–¢ store/floor ‚Äî –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    }
                )

            new_synced = list(synced | set(to_send))
            synced_count = len(new_synced)

            # üîÑ v5.1: partial (–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ < target) –∏–ª–∏ synced (–≤—Å–µ target —Ñ–æ—Ç–æ)
            new_status = 'synced' if synced_count >= target else 'partial'

            db.execute("""
                UPDATE raw_products
                SET ximilar_status = %s,
                    ximilar_synced_urls = %s,
                    ximilar_synced_at = NOW()
                WHERE id = %s
            """, new_status, json.dumps(new_synced), product.id)

        except Exception as e:
            db.execute("""
                UPDATE raw_products
                SET ximilar_status = 'error', error_message = %s
                WHERE id = %s
            """, str(e), product.id)
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π

```
/opt/unde/ximilar-sync/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ celery_app.py
‚îÇ   ‚îú‚îÄ‚îÄ tasks.py
‚îÇ   ‚îú‚îÄ‚îÄ ximilar_client.py
‚îÇ   ‚îî‚îÄ‚îÄ db.py
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ health-check.sh
‚îÇ   ‚îî‚îÄ‚îÄ test-sync.sh
‚îî‚îÄ‚îÄ deploy/
    ‚îî‚îÄ‚îÄ netplan-private.yaml
```

---

## 5. COLLAGE SERVER (‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç)

### –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|
| **Hostname** | collage |
| **Private IP** | 10.1.0.16 |
| **Public IP** | 65.109.172.52 |
| **–¢–∏–ø** | Hetzner CX33 |
| **vCPU** | 4 |
| **RAM** | 8 GB |
| **Disk** | 80 GB NVMe |
| **OS** | Ubuntu 24.04 LTS |
| **Git** | http://gitlab-real.unde.life/unde/collage.git |
| **–°—Ç–∞—Ç—É—Å** | ‚úÖ –†–∞–∑–≤—ë—Ä–Ω—É—Ç, –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã running |

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–æ—Ç–æ –¥–ª—è virtual try-on ‚Äî –æ–¥–∏–Ω –∫–æ–ª–ª–∞–∂ –Ω–∞ SKU:
- –°–∫–∞—á–∏–≤–∞–Ω–∏–µ **–≤—Å–µ—Ö** –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ SKU –∏–∑ Object Storage
- –°–∫–ª–µ–π–∫–∞ –≤ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π –∫–æ–ª–ª–∞–∂ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ, JPEG q=95, 4:4:4)
- Upload –∫–æ–ª–ª–∞–∂–∞ –≤ Object Storage
- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ collage_url –≤ Staging DB

### –ß—Ç–æ —Ç–∞–∫–æ–µ –∫–æ–ª–ª–∞–∂

```
–í—Å–µ —Ñ–æ—Ç–æ –æ–¥–Ω–æ–≥–æ SKU (image_urls –∏–∑ raw_products):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1  ‚îÇ ‚îÇ  2  ‚îÇ ‚îÇ  3  ‚îÇ ‚îÇ  4  ‚îÇ  ... —Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å
‚îÇ–ø–µ—Ä–µ–¥‚îÇ ‚îÇ –∑–∞–¥ ‚îÇ ‚îÇ –±–æ–∫ ‚îÇ ‚îÇ–¥–µ—Ç–∞–ª‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è —Å–∫–ª–µ–π–∫–∞ (–±–µ–∑ —É–º–µ–Ω—å—à–µ–Ω–∏—è!)
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
    ‚îÇ ‚îÇ 1 ‚îÇ ‚îÇ 2 ‚îÇ ‚îÇ 3 ‚îÇ ‚îÇ 4 ‚îÇ ... ‚îÇ
    ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
    ‚îÇ  JPEG q=95, –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ     ‚îÇ
    ‚îÇ  —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ, 4:4:4           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
            fal.ai try-on –ø–æ–ª—É—á–∞–µ—Ç
            –≤—Å–µ —Ä–∞–∫—É—Ä—Å—ã SKU –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ

–í–ê–ñ–ù–û: —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ù–ï —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è. –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–ª–ª–∞–∂–∞
–Ω–∞–ø—Ä—è–º—É—é –≤–ª–∏—è–µ—Ç –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ virtual try-on.
```

### –ó–∞–¥–∞—á–∏

| –ó–∞–¥–∞—á–∞ | –ß–∞—Å—Ç–æ—Ç–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|---------|----------|
| **process_new** | –ö–∞–∂–¥—ã–µ 15 –º–∏–Ω | –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–≤–∞—Ä—ã —Å image_status='uploaded' |
| **retry_failed** | –ö–∞–∂–¥—ã–π —á–∞—Å (:30) | –ü–æ–≤—Ç–æ—Ä–∏—Ç—å –Ω–µ—É–¥–∞—á–Ω—ã–µ (image_status='error') |
| **cleanup_temp** | –ï–∂–µ–¥–Ω–µ–≤–Ω–æ 04:00 | –û—á–∏—Å—Ç–∏—Ç—å /app/data |

### Docker Compose

```yaml
services:
  collage-worker:
    build: .
    container_name: collage-worker
    restart: unless-stopped
    command: celery -A app.celery_app worker --loglevel=info --concurrency=2
    env_file: .env
    volumes:
      - ./app:/app/app
      - ./data:/app/data
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 1G

  collage-beat:
    build: .
    container_name: collage-beat
    restart: unless-stopped
    command: celery -A app.celery_app beat --loglevel=info --schedule=/app/data/celerybeat-schedule
    env_file: .env
    volumes:
      - ./app:/app/app
      - ./data:/app/data
```

> node_exporter v1.8.2 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–∞–∫ systemd —Å–µ—Ä–≤–∏—Å (0.0.0.0:9100), –Ω–µ –≤ Docker.

### Environment Variables

```bash
# /opt/unde/collage/.env

STAGING_DB_URL=postgresql://collage:<password>@10.1.0.8:6432/unde_staging
REDIS_URL=redis://:<password>@10.1.0.4:6379/8
S3_ENDPOINT=https://hel1.your-objectstorage.com
S3_ACCESS_KEY=<access_key>
S3_SECRET_KEY=<secret_key>
S3_BUCKET=unde-images
BATCH_SIZE=100
COLLAGE_QUALITY=95
```

### –ü—Ä–æ—Ü–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏

```python
def process_sku(product_id: int):
    """–°–∫–ª–µ–∏—Ç—å –≤—Å–µ —Ñ–æ—Ç–æ –æ–¥–Ω–æ–≥–æ SKU –≤ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π –∫–æ–ª–ª–∞–∂."""
    product = db.query(
        "SELECT id, external_id, brand, image_urls FROM raw_products "
        "WHERE id = %s AND image_status = 'uploaded'", product_id)

    # –°–∫–∞—á–∞—Ç—å –í–°–ï –æ—Ä–∏–≥–∏–Ω–∞–ª—ã —ç—Ç–æ–≥–æ SKU –∏–∑ S3
    images = [Image.open(s3.download(url)) for url in product.image_urls]

    # –ü—Ä–∏–≤–µ—Å—Ç–∏ –∫ –æ–¥–Ω–æ–π –≤—ã—Å–æ—Ç–µ (max), —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
    target_height = max(img.height for img in images)
    resized = []
    for img in images:
        ratio = target_height / img.height
        resized.append(img.resize((int(img.width * ratio), target_height), Image.LANCZOS))

    # –°–∫–ª–µ–∏—Ç—å –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏
    total_width = sum(r.width for r in resized)
    collage = Image.new('RGB', (total_width, target_height), (255, 255, 255))
    x = 0
    for r in resized:
        collage.paste(r, (x, 0))
        x += r.width

    # JPEG q=95, subsampling=0 (4:4:4) ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
    buf = BytesIO()
    collage.save(buf, format='JPEG', quality=95, subsampling=0)

    # Upload –∏ –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å
    key = f"collages/{product.brand}/{product.external_id}.jpg"
    s3.upload_fileobj(buf, S3_BUCKET, key)
    collage_url = f"https://unde-images.hel1.your-objectstorage.com/{key}"
    db.execute(
        "UPDATE raw_products SET collage_url = %s, image_status = 'collage_ready', "
        "updated_at = NOW() WHERE id = %s", collage_url, product.id)
```

---

## 6. STAGING DB SERVER (‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç)

### –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|
| **Hostname** | staging-db |
| **Private IP** | 10.1.0.8 |
| **Public IP** | 89.167.91.76 |
| **–¢–∏–ø** | Hetzner CPX22 |
| **vCPU** | 4 |
| **RAM** | 8 GB |
| **Disk** | 80 GB SSD |
| **OS** | Ubuntu 24.04 LTS |
| **Git** | http://gitlab-real.unde.life/unde/Staging-DB.git |
| **–°—Ç–∞—Ç—É—Å** | ‚úÖ –†–∞–∑–≤—ë—Ä–Ω—É—Ç, PG17 + PgBouncer running |

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö:
- –î–∞–Ω–Ω—ã–µ –æ—Ç Apify (–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–æ–≤)
- –î–∞–Ω–Ω—ã–µ –æ—Ç Mobile API (–Ω–∞–ª–∏—á–∏–µ –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö)
- URLs —Ñ–æ—Ç–æ –≤ Object Storage
- –õ–æ–≥–∏ —Å–∫—Ä–∞–ø–µ—Ä–æ–≤

### –°—Ö–µ–º–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

```sql
-- DATABASE: unde_staging

-- –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–æ–≤
CREATE TABLE raw_products (
    id BIGSERIAL PRIMARY KEY,
    
    source VARCHAR(50) NOT NULL,
    external_id VARCHAR(100) NOT NULL,
    brand VARCHAR(50) NOT NULL,
    
    name TEXT,
    description TEXT,
    price DECIMAL(10,2),
    currency VARCHAR(10) DEFAULT 'AED',
    category TEXT,
    colour VARCHAR(100),
    sizes JSONB,
    composition TEXT,
    
    original_image_urls JSONB,
    image_urls JSONB,
    collage_url TEXT,
    
    raw_data JSONB,
    scraped_at TIMESTAMPTZ NOT NULL,
    
    image_status VARCHAR(20) DEFAULT 'pending',
        -- pending ‚Üí uploaded ‚Üí collage_ready | error
    
    sync_status VARCHAR(20) DEFAULT 'pending',
        -- pending ‚Üí synced | skipped | error
    
    ximilar_status VARCHAR(20) DEFAULT 'pending',
        -- pending ‚Üí partial ‚Üí synced | error
        -- üîÑ v5.1: partial = –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ < target —Ñ–æ—Ç–æ (progressive ingestion)
    ximilar_synced_at TIMESTAMPTZ,

    -- üîÑ v5.1: –Ω–æ–≤—ã–µ –ø–æ–ª—è –¥–ª—è selective sync –∏ progressive ingestion
    index_scope TEXT DEFAULT 'off',
        -- 'pilot' = –≥—Ä—É–∑–∏—Ç—å –≤ Ximilar, 'pgvector' = —Ç–æ–ª—å–∫–æ pgvector, 'off' = –Ω–µ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å
    ximilar_synced_urls JSONB DEFAULT '[]',
        -- URL'—ã —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –≤ Ximilar (idempotency)
    ximilar_target_count SMALLINT DEFAULT 2,
        -- —Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ –≥—Ä—É–∑–∏—Ç—å (2 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –ø–æ–≤—ã—à–∞–µ—Ç—Å—è progressive ingestion)
    
    synced_at TIMESTAMPTZ,
    error_message TEXT,
    
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    
    UNIQUE(source, external_id)
);

-- –ù–∞–ª–∏—á–∏–µ –≤ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –º–∞–≥–∞–∑–∏–Ω–∞—Ö
CREATE TABLE raw_availability (
    id BIGSERIAL PRIMARY KEY,
    brand VARCHAR(50) NOT NULL,
    store_id INTEGER NOT NULL,
    product_id VARCHAR(100) NOT NULL,
    sizes_in_stock JSONB NOT NULL,
    fetched_at TIMESTAMPTZ NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Expression UNIQUE: PG –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç cast –≤ UNIQUE constraint –Ω–∞–ø—Ä—è–º—É—é
CREATE FUNCTION to_date_immutable(ts TIMESTAMPTZ) RETURNS DATE AS $$
    SELECT (ts AT TIME ZONE 'UTC')::date;
$$ LANGUAGE SQL IMMUTABLE;

CREATE UNIQUE INDEX idx_raw_availability_unique_daily
    ON raw_availability(brand, store_id, product_id, to_date_immutable(fetched_at));

-- –§–∏–∑–∏—á–µ—Å–∫–∏–µ –º–∞–≥–∞–∑–∏–Ω—ã Dubai
CREATE TABLE raw_stores (
    id SERIAL PRIMARY KEY,
    brand VARCHAR(50) NOT NULL,
    store_id INTEGER NOT NULL,
    name TEXT,
    address TEXT,
    city VARCHAR(100) DEFAULT 'Dubai',
    country VARCHAR(10) DEFAULT 'AE',
    mall_name TEXT,
    latitude DECIMAL(10,7),
    longitude DECIMAL(10,7),
    created_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(brand, store_id)
);

-- –õ–æ–≥–∏ —Å–∫—Ä–∞–ø–µ—Ä–æ–≤
CREATE TABLE scraper_logs (
    id BIGSERIAL PRIMARY KEY,
    scraper_name VARCHAR(100) NOT NULL,
    run_id VARCHAR(100),
    status VARCHAR(20) NOT NULL,
    records_fetched INTEGER DEFAULT 0,
    records_new INTEGER DEFAULT 0,
    records_updated INTEGER DEFAULT 0,
    records_errors INTEGER DEFAULT 0,
    started_at TIMESTAMPTZ NOT NULL,
    completed_at TIMESTAMPTZ,
    duration_seconds INTEGER,
    error_message TEXT,
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- –ò–ù–î–ï–ö–°–´
CREATE INDEX idx_raw_products_brand ON raw_products(brand);
CREATE INDEX idx_raw_products_image_status ON raw_products(image_status);
CREATE INDEX idx_raw_products_sync_status ON raw_products(sync_status);
CREATE INDEX idx_raw_products_ximilar_status ON raw_products(ximilar_status);
CREATE INDEX idx_raw_products_external_id ON raw_products(external_id);
CREATE INDEX idx_raw_products_scraped_at ON raw_products(scraped_at);
CREATE INDEX idx_raw_availability_brand_store ON raw_availability(brand, store_id);
CREATE INDEX idx_raw_availability_product ON raw_availability(product_id);
CREATE INDEX idx_raw_availability_fetched ON raw_availability(fetched_at);

-- üîÑ v5.1: –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è availability post-filter (Step 3.5 Recognition Pipeline)
CREATE INDEX IF NOT EXISTS idx_raw_availability_lookup
    ON raw_availability (brand, store_id, product_id, fetched_at DESC);
CREATE INDEX IF NOT EXISTS idx_raw_availability_brand_product
    ON raw_availability (brand, product_id);
CREATE INDEX idx_scraper_logs_name ON scraper_logs(scraper_name);
CREATE INDEX idx_scraper_logs_started ON scraper_logs(started_at DESC);
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è PostgreSQL

```ini
# /etc/postgresql/17/main/conf.d/staging.conf

shared_buffers = 1GB
effective_cache_size = 3GB
work_mem = 16MB
maintenance_work_mem = 256MB
listen_addresses = '127.0.0.1'
port = 5432
max_connections = 100
synchronous_commit = off
checkpoint_completion_target = 0.9
wal_level = minimal
max_wal_senders = 0
archive_mode = off
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è PgBouncer

```ini
[databases]
unde_staging = host=127.0.0.1 port=5432 dbname=unde_staging

[pgbouncer]
listen_addr = 10.1.0.8
listen_port = 6432
auth_type = scram-sha-256
pool_mode = transaction
max_client_conn = 200
default_pool_size = 10
```

### –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –ë–î

| User | –î–æ—Å—Ç—É–ø | –°–µ—Ä–≤–µ—Ä |
|------|--------|--------|
| apify | READ/WRITE raw_products, scraper_logs | Apify Server |
| downloader | READ/WRITE raw_products (image_status, image_urls) | Photo Downloader |
| ximilar | READ/WRITE raw_products (ximilar_status) | Ximilar Sync Server |
| scraper | READ/WRITE all | Scraper Server |
| collage | READ/WRITE raw_products | Collage Server |

### –î–æ—Å—Ç—É–ø—ã

| –°–µ—Ä–≤–µ—Ä | IP | –î–æ—Å—Ç—É–ø |
|--------|-----|--------|
| Apify Server | 10.1.0.9 | ‚úÖ |
| Photo Downloader | 10.1.0.10 | ‚úÖ |
| Ximilar Sync | 10.1.0.11 | ‚úÖ |
| Scraper Server | 10.1.0.3 | ‚úÖ |
| Collage Server | 10.1.0.16 | ‚úÖ |
| Production DB | 10.1.1.2 | ‚ùå |
| App Server | 10.1.0.2 | ‚ùå |

---

## 7. HETZNER OBJECT STORAGE

### –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|
| **Bucket** | unde-images |
| **Endpoint** | https://hel1.your-objectstorage.com |
| **Region** | Helsinki (hel1) |

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ bucket

```
unde-images/
‚îú‚îÄ‚îÄ originals/
‚îÇ   ‚îú‚îÄ‚îÄ zara/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 495689099/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1.jpg  2.jpg  3.jpg  4.jpg  5.jpg
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ bershka/
‚îÇ   ‚îú‚îÄ‚îÄ pullandbear/
‚îÇ   ‚îú‚îÄ‚îÄ stradivarius/
‚îÇ   ‚îú‚îÄ‚îÄ massimodutti/
‚îÇ   ‚îî‚îÄ‚îÄ oysho/
‚îî‚îÄ‚îÄ collages/
    ‚îú‚îÄ‚îÄ zara/
    ‚îÇ   ‚îú‚îÄ‚îÄ 495689099.jpg
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îú‚îÄ‚îÄ bershka/
    ‚îî‚îÄ‚îÄ ...
```

### URLs

```
–û—Ä–∏–≥–∏–Ω–∞–ª:  https://unde-images.hel1.your-objectstorage.com/originals/zara/495689099/1.jpg
–ö–æ–ª–ª–∞–∂:    https://unde-images.hel1.your-objectstorage.com/collages/zara/495689099.jpg
```

### –†–∞—Å—á—ë—Ç –æ–±—ä—ë–º–∞ (MVP ‚Äî Dubai, Inditex)

| –ë—Ä–µ–Ω–¥ | –¢–æ–≤–∞—Ä–æ–≤ | –û—Ä–∏–≥–∏–Ω–∞–ª—ã (5x300KB) | –ö–æ–ª–ª–∞–∂–∏ (700KB) | –ò—Ç–æ–≥–æ |
|-------|---------|---------------------|-----------------|-------|
| Zara | 15,000 | 22.5 GB | 10.5 GB | 33 GB |
| Bershka | 8,000 | 12 GB | 5.6 GB | 17.6 GB |
| Pull&Bear | 6,000 | 9 GB | 4.2 GB | 13.2 GB |
| Stradivarius | 8,000 | 12 GB | 5.6 GB | 17.6 GB |
| Massimo Dutti | 5,000 | 7.5 GB | 3.5 GB | 11 GB |
| Oysho | 5,000 | 7.5 GB | 3.5 GB | 11 GB |
| **–ò—Ç–æ–≥–æ** | **47,000** | **70.5 GB** | **32.9 GB** | **~103 GB** |

### Object Storage –¥–æ—Å—Ç—É–ø—ã

| Bucket | GET (—á—Ç–µ–Ω–∏–µ) | PUT/DELETE (–∑–∞–ø–∏—Å—å) | LIST (–ª–∏—Å—Ç–∏–Ω–≥) |
|--------|-------------|---------------------|----------------|
| **unde-images** (–∫–∞—Ç–∞–ª–æ–≥) | –ü—É–±–ª–∏—á–Ω—ã–π | –¢–æ–ª—å–∫–æ —Å Access Key | –û—Ç–∫–ª—é—á–µ–Ω |
| **unde-user-media** (—é–∑–µ—Ä—ã) | –¢–æ–ª—å–∫–æ —Å Access Key (–ø—Ä–∏–≤–∞—Ç–Ω—ã–π) | –¢–æ–ª—å–∫–æ —Å Access Key | –û—Ç–∫–ª—é—á–µ–Ω |

### Bucket: unde-user-media ‚úÖ

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** —Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –º–µ–¥–∏–∞ ‚Äî —Ñ–æ—Ç–æ —é–∑–µ—Ä–∞, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã try-on, —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—ã. –ü—Ä–∏–≤–∞—Ç–Ω—ã–π –¥–æ—Å—Ç—É–ø (–≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –∫–∞—Ç–∞–ª–æ–∂–Ω–æ–≥–æ bucket).

**–í–∞–∂–Ω–æ:** thumbnail (200px) –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –Ω–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–µ (Flutter) –ø—Ä–∏ upload. –û–±–∞ —Ñ–∞–π–ª–∞ (original + thumb) –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ –∏ –∫–ª–∞–¥—É—Ç—Å—è –≤ bucket. –ù–æ–ª—å –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ –±—ç–∫–µ–Ω–¥ –¥–ª—è —Ä–µ—Å–∞–π–∑–∞.

```
unde-user-media/
‚îú‚îÄ‚îÄ {user_id}/
‚îÇ   ‚îú‚îÄ‚îÄ photos/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ {photo_id}/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ original.jpg    (~500KB-2MB)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ thumb.jpg       (~10KB, 200px)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ tryon/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ {tryon_id}/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ result.jpg      (~300KB-1MB)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ thumb.jpg       (~10KB, 200px)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ saved/
‚îÇ       ‚îú‚îÄ‚îÄ {outfit_id}/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ original.jpg
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ thumb.jpg
‚îÇ       ‚îî‚îÄ‚îÄ ...
```

### –†–∞—Å—á—ë—Ç –æ–±—ä—ë–º–∞ User Media (MVP)

| –î–∞–Ω–Ω—ã–µ | –ù–∞ —é–∑–µ—Ä–∞ | 1K —é–∑–µ—Ä–æ–≤ | 10K —é–∑–µ—Ä–æ–≤ |
|--------|----------|-----------|------------|
| –§–æ—Ç–æ (original + thumb) | ~10 MB | ~10 GB | ~100 GB |
| Try-on —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã | ~5 MB | ~5 GB | ~50 GB |
| –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—ã | ~3 MB | ~3 GB | ~30 GB |
| **–ò—Ç–æ–≥–æ** | **~18 MB** | **~18 GB** | **~180 GB** |

---
